\section{Applications}
\label{sec:introduction_applications}

While Chapters~\ref{ch:pybel},~\ref{ch:belcommons},~\ref{ch:recuration}, and ~\ref{ch:bio2bel} cover the generation, enrichment, and exploration of biological knowledge graphs, Chapters~\ref{ch:bel2abm},~\ref{ch:guiltytargets}, and ~\ref{ch:epicom} cover three areas in which biological knowledge graphs can be used to support drug discovery.
While there have been many previous computational, network-based methods that have been used for these purposes, most rely on narrowly-focused databases with low granularity or slow update.
The final chapters focus on adapting these methods to higher granularity knowledge encoded in BEL for the drug repositioning task in which a new indication is proposed for a previously clinically studied chemical.
Further, these approaches can be carefully adapted for precision medicine, in which the use of a given drug should be prescribed to a given patient of subgroup of patients instead of an entire population.

\subsection{Simulation}

One of the most simple simulations of biological systems came with the advent of Petri Nets~\cite{Peterson1977}.
In these graphical models, nodes have boolean states that change through time based on logical rules encoded in the model.
However, these models are limited in their expressive power.

One of the most powerful simulations of biological systems comes from partial differential equations, which the ability to precisely encode both spatial and temporal events as well as their evolution though time.
However, they suffer the drawbacks that they have a high number of unknown parameters either due to the lack of available experimental data, or due to unknown intermediate processes.
Further, fitting differential equations with high number of variables (more than several hundred) was completely inaccessible until recently.

Agent-based models provide an intermediate in which a small set of rules can be used to infer emergent properties of a system through simulation and optimization.
However, their definition is painstaking, and it is difficult to include the most relevant biological knowledge.
Chapter~\ref{ch:bel2abm} explores one way biological knowledge can be used to influence the generation and application of these types of models to understanding basic biological processes in \ac{AD}.

\subsection{Target Prioritization}

Target prioritization is the task of ranking proteins based on their relevance to a given disease and likelihood of being a successful therapeutic target.
However, it does not directly assess ligandability nor druggability, so computational approaches must be complemented by both the appropriate functional experiments (e.g., knockdown studies) and physical studies (e.g., binding assays).

Many target prioritization techniques rely on the principle of guilt-by-association, which assumes that similar proteins have similar functions and therefore candidates can be proposed on their similarity to previously known targets.
While this concerns guilt-by-association methods may be limited in their ability to prioritize novel targets, they are still considered robust~\cite{Moreau2012}.

Chapter~\ref{ch:guiltytargets} explores a novel method for calculating the similarities between proteins based on network representation learning and improving the state-of-the-art pipeline presented by Emig \textit{et al.}~\cite{Emig2013}.
While initial work used the same protein-protein interaction networks and disease-specific differential gene expression profiles, it can be extended to accomodate the rich knowledge encoded in \ac{BEL} networks generated by manual, semi-automated, and automated approaches described elsewhere in this thesis.

\subsection{Mechanism of Action Deconvolution}

Understanding the mechanism of action of a given compound not only gives insight into its efficacy in a given therapeutic indication but also its possible off-target effects.
Many of those effects may be harmful to a patient, and are often studied through the lens of toxicology~\cite{Lee2013}.
Historically, these investigations have remained target-centric and have yet to access the mechanistic causal knowledge contained within biological knowledge graphs.
It follows that a better mechanistic understanding of off-target effects could be useful in not only mitigating off-target effects (and ultimately side effects of therapies) but also in proposing alternate usages through the lens of drug repositioning.

The network representation learning techniques are well-suited to capture patterns in compound-target pairs, but also the high granularity mechanistic causal knowledge graphs whose generation is described in this thesis.
The embeddings generated for nodes and edges can be directly applied to the drug repositioning task by scoring the likelihood of an edge existing between a previously studied drug and a disease both existing within a network of drugs, targets, diseases, drug-target-interactions, and disease-target associations.
While this simple approach has been described in several papers, network representation learning methods allow for the easy incorporation of new entities and relation types, such as side effects and drug-side effect annotations.
Further, the constraints of drug repositioning can be related to solve the more general problem of drug discovery, which involves assessing the liklihood of the existence of an edge between any chemical and any disease.
Upcoming methods in network representation learning such as the inclusion of literals~\cite{Kristiadi2018} into the learning process can allow for the incorporation of physiochemical properties of chemicals as well as fingerprints that are more common in chemogenomics and proteochemometrics to be included implicitly in the learning process.

In order to generate efficacious therapies, mechanism of action deconvolution must be paired with knowledge about the underlying aetiological mechanisms of disease.
In the field of neurodegenerative diseases, this task is severely limited by knowledge about the diseases.
NeuroMMSig provides not only high-quality manually curated candidate mechanisms for \ac{AD}, \ac{PD}, and epilepsy as biological knowledge graphs in \ac{BEL}, but also an enrichment algorithm that goes beyond the most basic and common described by~\cite{Khatri2012} in order to incorporate the mechanistic causal information contained in the underlying knowledge graphs.

The NeuroMMSig knowledge graphs and enrichment algorithm are used in Chapter~\ref{ch:epicom} to deconvolute the mechanism of action of the anti-epileptic, carbamazepine, that has also shown therapeutic effect in \ac{AD}.
It ranked disease-specific mechanisms in \ac{AD} and epilepsy that are likely targeted by carbamazepine and ultimately lead to the hypothesis that the GABA-ergic receptor pathway was central to its multi-indication effect.
Importantly, this investigation was advantageous over black-box machine learning models because the underlying knowledge assemblies are self-explanatory and based on papers published in molecular biology and epidemiology.

Finally, at the conclusion of this thesis, the implications of moving from single targets to entire mechanisms as motivated by the target prioritization and mechanism of deconvolution chapters for future drug repositioning and drug discovery is considered.
