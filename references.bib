@article{Zerbino2018,
    abstract = {The Ensembl project has been aggregating, processing, integrating and redistributing genomic datasets since the initial releases of the draft human genome, with the aim of accelerating genomics research through rapid open distribution of public data. Large amounts of raw data are thus transformed into knowledge, which is made available via a multitude of channels, in particular our browser (http://www.ensembl.org). Over time, we have expanded in multiple directions. First, our resources describe multiple fields of genomics, in particular gene annotation, comparative genomics, genetics and epigenomics. Second, we cover a growing number of genome assemblies; Ensembl Release 90 contains exactly 100. Third, our databases feed simultaneously into an array of services designed around different use cases, ranging from quick browsing to genome-wide bioinformatic analysis. We present here the latest developments of the Ensembl project, with a focus on managing an increasing number of assemblies, supporting efforts in genome interpretation and improving our browser.},
    author = {Zerbino, Daniel R and Achuthan, Premanand and Akanni, Wasiu and Amode, M Ridwan and Barrell, Daniel and Bhai, Jyothish and Billis, Konstantinos and Cummins, Carla and Gall, Astrid and Gir { \' { o } } n, Carlos Garc { \' { i } } a and Gil, Laurent and Gordon, Leo and Haggerty, Leanne and Haskell, Erin and Hourlier, Thibaut and Izuogu, Osagie G and Janacek, Sophie H and Juettemann, Thomas and To, Jimmy Kiang and Laird, Matthew R and Lavidas, Ilias and Liu, Zhicheng and Loveland, Jane E and Maurel, Thomas and McLaren, William and Moore, Benjamin and Mudge, Jonathan and Murphy, Daniel N and Newman, Victoria and Nuhn, Michael and Ogeh, Denye and Ong, Chuang Kee and Parker, Anne and Patricio, Mateus and Riat, Harpreet Singh and Schuilenburg, Helen and Sheppard, Dan and Sparrow, Helen and Taylor, Kieron and Thormann, Anja and Vullo, Alessandro and Walts, Brandon and Zadissa, Amonida and Frankish, Adam and Hunt, Sarah E and Kostadima, Myrto and Langridge, Nicholas and Martin, Fergal J and Muffato, Matthieu and Perry, Emily and Ruffier, Magali and Staines, Dan M and Trevanion, Stephen J and Aken, Bronwen L and Cunningham, Fiona and Yates, Andrew and Flicek, Paul},
    doi = {10.1093/nar/gkx1098},
    issn = {1362-4962},
    journal = {Nucleic Acids Res.},
    mendeley-groups = {Doctoral},
    month = {jan},
    number = {D1},
    pages = {D754--D761},
    pmid = {29155950},
    title = {{ Ensembl 2018. }},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/29155950 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5753206},
    volume = {46},
    year = {2018}
}
@article{Wright2005,
    abstract = {The HGNC Comparison of Orthology Predictions search tool, HCOP (http://www.gene.ucl.ac.uk/cgi-bin/nomenclature/hcop.pl ), enables users to compare predicted human and mouse orthologs for a specified gene, or set of genes, from either species according to the ortholog assertions from the Ensembl, HGNC, Homologene, Inparanoid, MGI and PhIGs databases. Users can assess the reliability of the prediction from the number of these different sources that identify a particular orthologous pair. HCOP provides a useful one-stop resource to summarise, compare and access various sources of human and mouse orthology data.},
    author = {Wright, Mathew W and Eyre, Tina A and Lush, Michael J and Povey, Sue and Bruford, Elspeth A},
    doi = {10.1007/s00335-005-0103-2},
    issn = {0938-8990},
    journal = {Mamm. Genome},
    mendeley-groups = {Doctoral},
    month = {nov},
    number = {11},
    pages = {827--8},
    pmid = {16284797},
    title = {{ HCOP: the HGNC comparison of orthology predictions search tool. }},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/16284797},
    volume = {16},
    year = {2005}
}
@article{Blake2017,
    abstract = {The Mouse Genome Database (MGD: http://www.informatics.jax.org) is the primary community data resource for the laboratory mouse. It provides a highly integrated and highly curated system offering a comprehensive view of current knowledge about mouse genes, genetic markers and genomic features as well as the associations of those features with sequence, phenotypes, functional and comparative information, and their relationships to human diseases. MGD continues to enhance access to these data, to extend the scope of data content and visualizations, and to provide infrastructure and user support that ensures effective and efficient use of MGD in the advancement of scientific knowledge. Here, we report on recent enhancements made to the resource and new features.},
    author = {Blake, Judith A. and Eppig, Janan T. and Kadin, James A. and Richardson, Joel E. and Smith, Cynthia L. and Bult, Carol J. and Anagnostopoulos, A. and Baldarelli, R. M. and Beal, J. S. and Bello, S. M. and Blodgett, O. and Butler, N. E. and Corbani, L. E. and Dene, H. and Drabkin, H. J. and Forthofer, K. L. and Giannatto, S. L. and Hale, P. and Hill, D. P. and Hutchins, L. and Knowlton, M. and Lavertu, A. and Law, M. and Lewis, J. R. and Lopez, V. and Maghini, D. and Perry, D. and McAndrews, M. and Miers, D. and Montenko, H. and Ni, L. and Onda, H. and Recla, J. M. and Reed, D. J. and Richards-Smith, B. and Sitnikov, D. and Tomczuk, M. and Wilming, L. and Zhu, Y.},
    doi = {10.1093/nar/gkw1040},
    file = {:Users/cthoyt/ownCloud/Mendeley/2017/Blake et al. - 2017 - Mouse Genome Database (MGD)-2017 Community knowledge resource for the laboratory mouse.pdf:pdf},
    issn = {13624962},
    journal = {Nucleic Acids Res.},
    mendeley-groups = {Doctoral},
    number = {D1},
    pages = {D723--D729},
    pmid = {27899570},
    title = {{ Mouse Genome Database (MGD)-2017: Community knowledge resource for the laboratory mouse }},
    volume = {45},
    year = {2017}
}
@article{Shimoyama2015,
    abstract = {The Rat Genome Database (RGD, http://rgd.mcw.edu) provides the most comprehensive data repository and informatics platform related to the laboratory rat, one of the most important model organisms for disease studies. RGD maintains and updates datasets for genomic elements such as genes, transcripts and increasingly in recent years, sequence variations, as well as map positions for multiple assemblies and sequence information. Functional annotations for genomic elements are curated from published literature, submitted by researchers and integrated from other public resources. Complementing the genomic data catalogs are those associated with phenotypes and disease, including strains, QTL and experimental phenotype measurements across hundreds of strains. Data are submitted by researchers, acquired through bulk data pipelines or curated from published literature. Innovative software tools provide users with an integrated platform to query, mine, display and analyze valuable genomic and phenomic datasets for discovery and enhancement of their own research. This update highlights recent developments that reflect an increasing focus on: (i) genomic variation, (ii) phenotypes and diseases, (iii) data related to the environment and experimental conditions and (iv) datasets and software tools that allow the user to explore and analyze the interactions among these and their impact on disease.},
    author = {Shimoyama, Mary and { De Pons } , Jeff and Hayman, G. Thomas and Laulederkind, Stanley J.F. and Liu, Weisong and Nigam, Rajni and Petri, Victoria and Smith, Jennifer R. and Tutaj, Marek and Wang, Shur Jen and Worthey, Elizabeth and Dwinell, Melinda and Jacob, Howard},
    doi = {10.1093/nar/gku1026},
    file = {:Users/cthoyt/ownCloud/Mendeley/2015/Shimoyama et al. - 2015 - The Rat Genome Database 2015 Genomic, phenotypic and environmental variations and disease.pdf:pdf},
    isbn = {0305-1048},
    issn = {13624962},
    journal = {Nucleic Acids Res.},
    mendeley-groups = {Doctoral},
    number = {D1},
    pages = {D743--D750},
    pmid = {25355511},
    title = {{ The Rat Genome Database 2015: Genomic, phenotypic and environmental variations and disease }},
    volume = {43},
    year = {2015}
}
@article{Yates2017,
    abstract = {The HUGO Gene Nomenclature Committee (HGNC) based at the European Bioinformatics Institute (EMBL-EBI) assigns unique symbols and names to human genes. Currently the HGNC database contains almost 40 000 approved gene symbols, over 19 000 of which represent protein-coding genes. In addition to naming genomic loci we manually curate genes into family sets based on shared characteristics such as homology, function or phenotype. We have recently updated our gene family resources and introduced new improved visualizations which can be seen alongside our gene symbol reports on our primary website http://www.genenames.org In 2016 we expanded our remit and formed the Vertebrate Gene Nomenclature Committee (VGNC) which is responsible for assigning names to vertebrate species lacking a dedicated nomenclature group. Using the chimpanzee genome as a pilot project we have approved symbols and names for over 14 500 protein-coding genes in chimpanzee, and have developed a new website http://vertebrate.genenames.org to distribute these data. Here, we review our online data and resources, focusing particularly on the improvements and new developments made during the last two years.},
    author = {Yates, Bethan and Braschi, Bryony and Gray, Kristian A. and Seal, Ruth L. and Tweedie, Susan and Bruford, Elspeth A.},
    doi = {10.1093/nar/gkw1033},
    file = {:Users/cthoyt/ownCloud/Mendeley/2017/Yates et al. - 2017 - Genenames.org The HGNC and VGNC resources in 2017.pdf:pdf},
    isbn = {13624962 (Electronic)},
    issn = {13624962},
    journal = {Nucleic Acids Res.},
    number = {D1},
    pages = {D619--D625},
    pmid = {27799471},
    title = {{ Genenames.org: The HGNC and VGNC resources in 2017 }},
    volume = {45},
    year = {2017}
}
@article{Maglott2011,
    abstract = {Entrez Gene (www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=gene) is NCBI's database for gene-specific information. It does not include all known or predicted genes; instead Entrez Gene focuses on the genomes that have been completely sequenced, that have an active research community to contribute gene-specific information, or that are scheduled for intense sequence analysis. The content of Entrez Gene represents the result of curation and automated integration of data from NCBI's Reference Sequence project (RefSeq), from collaborating model organism databases, and from many other databases available from NCBI. Records are assigned unique, stable and tracked integers as identifiers. The content (nomenclature, map location, gene products and their attributes, markers, phenotypes, and links to citations, sequences, variation details, maps, expression, homologs, protein domains and external databases) is updated as new information becomes available. Entrez Gene is a step forward from NCBI's LocusLink, with both a major increase in taxonomic scope and improved access through the many tools associated with NCBI Entrez.},
    author = {Maglott, Donna and Ostell, Jim and Pruitt, Kim D. and Tatusova, Tatiana},
    doi = {10.1093/nar/gkq1237},
    file = {:Users/cthoyt/ownCloud/Mendeley/2011/Maglott et al. - 2011 - Entrez gene Gene-centered information at NCBI.pdf:pdf},
    isbn = {1362-4962 (Electronic)$\backslash$n0305-1048 (Linking)},
    issn = {03051048},
    journal = {Nucleic Acids Res.},
    number = {SUPPL. 1},
    pages = {52--57},
    pmid = {15608257},
    title = {{ Entrez gene: Gene-centered information at NCBI }},
    volume = {39},
    year = {2011}
}

@article{Howe2013,
    abstract = {ZFIN, the Zebrafish Model Organism Database (http://zfin.org), is the central resource for zebrafish genetic, genomic, phenotypic and developmental data. ZFIN curators manually curate and integrate comprehensive data involving zebrafish genes, mutants, transgenics, phenotypes, genotypes, gene expressions, morpholinos, antibodies, anatomical structures and publications. Integrated views of these data, as well as data gathered through collaborations and data exchanges, are provided through a wide selection of web-based search forms. Among the vertebrate model organisms, zebrafish are uniquely well suited for rapid and targeted generation of mutant lines. The recent rapid production of mutants and transgenic zebrafish is making management of data associated with these resources particularly important to the research community. Here, we describe recent enhancements to ZFIN aimed at improving our support for mutant and transgenic lines, including (i) enhanced mutant/transgenic search functionality; (ii) more expressive phenotype curation methods; (iii) new downloads files and archival data access; (iv) incorporation of new data loads from laboratories undertaking large-scale generation of mutant or transgenic lines and (v) new GBrowse tracks for transgenic insertions, genes with antibodies and morpholinos.},
    author = {Howe, Douglas G and Bradford, Yvonne M and Conlin, Tom and Eagle, Anne E and Fashena, David and Frazer, Ken and Knight, Jonathan and Mani, Prita and Martin, Ryan and Moxon, Sierra A Taylor and Paddock, Holly and Pich, Christian and Ramachandran, Sridhar and Ruef, Barbara J and Ruzicka, Leyla and Schaper, Kevin and Shao, Xiang and Singer, Amy and Sprunger, Brock and { Van Slyke } , Ceri E and Westerfield, Monte},
    doi = {10.1093/nar/gks938},
    issn = {1362-4962},
    journal = {Nucleic acids research},
    mendeley-groups = {Thesis try 2},
    month = {jan},
    number = {Database issue},
    pages = {D854--60},
    pmid = {23074187},
    title = {{ ZFIN, the Zebrafish Model Organism Database: increased support for mutants and transgenics. }},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/23074187 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3531097},
    volume = {41},
    year = {2013}
}
@article{Thurmond2019,
    abstract = {FlyBase (flybase.org) is a knowledge base that supports the community of researchers that use the fruit fly, Drosophila melanogaster, as a model organism. The FlyBase team curates and organizes a diverse array of genetic, molecular, genomic, and developmental information about Drosophila. At the beginning of 2018, 'FlyBase 2.0' was released with a significantly improved user interface and new tools. Among these important changes are a new organization of search results into interactive lists or tables (hitlists), enhanced reference lists, and new protein domain graphics. An important new data class called 'experimental tools' consolidates information on useful fly strains and other resources related to a specific gene, which significantly enhances the ability of the Drosophila researcher to design and carry out experiments. With the release of FlyBase 2.0, there has also been a restructuring of backend architecture and a continued development of application programming interfaces (APIs) for programmatic access to FlyBase data. In this review, we describe these major new features and functionalities of the FlyBase 2.0 site and how they support the use of Drosophila as a model organism for biological discovery and translational research.},
    author = {Thurmond, Jim and Goodman, Joshua L and Strelets, Victor B and Attrill, Helen and Gramates, L Sian and Marygold, Steven J and Matthews, Beverley B and Millburn, Gillian and Antonazzo, Giulia and Trovisco, Vitor and Kaufman, Thomas C and Calvi, Brian R and { FlyBase Consortium }},
    doi = {10.1093/nar/gky1003},
    issn = {1362-4962},
    journal = {Nucleic acids research},
    mendeley-groups = {Thesis try 2},
    month = {jan},
    number = {D1},
    pages = {D759--D765},
    pmid = {30364959},
    title = {{ FlyBase 2.0: the next generation. }},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/30364959 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC6323960},
    volume = {47},
    year = {2019}
}
@article{Cherry2012,
    abstract = {The Saccharomyces Genome Database (SGD, http://www.yeastgenome.org) is the community resource for the budding yeast Saccharomyces cerevisiae. The SGD project provides the highest-quality manually curated information from peer-reviewed literature. The experimental results reported in the literature are extracted and integrated within a well-developed database. These data are combined with quality high-throughput results and provided through Locus Summary pages, a powerful query engine and rich genome browser. The acquisition, integration and retrieval of these data allow SGD to facilitate experimental design and analysis by providing an encyclopedia of the yeast genome, its chromosomal features, their functions and interactions. Public access to these data is provided to researchers and educators via web pages designed for optimal ease of use.},
    author = {Cherry, J Michael and Hong, Eurie L and Amundsen, Craig and Balakrishnan, Rama and Binkley, Gail and Chan, Esther T and Christie, Karen R and Costanzo, Maria C and Dwight, Selina S and Engel, Stacia R and Fisk, Dianna G and Hirschman, Jodi E and Hitz, Benjamin C and Karra, Kalpana and Krieger, Cynthia J and Miyasato, Stuart R and Nash, Rob S and Park, Julie and Skrzypek, Marek S and Simison, Matt and Weng, Shuai and Wong, Edith D},
    doi = {10.1093/nar/gkr1029},
    issn = {1362-4962},
    journal = {Nucleic acids research},
    mendeley-groups = {Thesis try 2},
    month = {jan},
    number = {Database issue},
    pages = {D700--5},
    pmid = {22110037},
    title = {{ Saccharomyces Genome Database: the genomics resource of budding yeast. }},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/22110037 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3245034},
    volume = {40},
    year = {2012}
}
@article{Karimi2018,
    author = {Karimi, Kamran and Fortriede, Joshua D and Lotay, Vaneet S and Burns, Kevin A and Wang, Dong Zhou and Fisher, Malcom E and Pells, Troy J and James-Zorn, Christina and Wang, Ying and Ponferrada, V G and Chu, Stanley and Chaturvedi, Praneet and Zorn, Aaron M and Vize, Peter D},
    doi = {10.1093/nar/gkx936},
    issn = {0305-1048},
    journal = {Nucleic Acids Research},
    mendeley-groups = {Thesis try 2},
    month = {jan},
    number = {D1},
    pages = {D861--D868},
    title = {{ Xenbase: a genomic, epigenomic and transcriptomic model organism database }},
    url = {http://academic.oup.com/nar/article/46/D1/D861/4559118},
    volume = {46},
    year = {2018}
}
@article{Bult2019,
    abstract = {The Mouse Genome Database (MGD; http://www.informatics.jax.org) is the community model organism genetic and genome resource for the laboratory mouse. MGD is the authoritative source for biological reference data sets related to mouse genes, gene functions, phenotypes, and mouse models of human disease. MGD is the primary outlet for official gene, allele and mouse strain nomenclature based on the guidelines set by the International Committee on Standardized Nomenclature for Mice. In this report we describe significant enhancements to MGD, including two new graphical user interfaces: (i) the Multi Genome Viewer for exploring the genomes of multiple mouse strains and (ii) the Phenotype-Gene Expression matrix which was developed in collaboration with the Gene Expression Database (GXD) and allows researchers to compare gene expression and phenotype annotations for mouse genes. Other recent improvements include enhanced efficiency of our literature curation processes and the incorporation of Transcriptional Start Site (TSS) annotations from RIKEN's FANTOM 5 initiative.},
    author = {Bult, Carol J and Blake, Judith A and Smith, Cynthia L and Kadin, James A and Richardson, Joel E and { Mouse Genome Database Group }},
    doi = {10.1093/nar/gky1056},
    issn = {1362-4962},
    journal = {Nucleic acids research},
    mendeley-groups = {Thesis try 2},
    month = {jan},
    number = {D1},
    pages = {D801--D806},
    pmid = {30407599},
    title = {{ Mouse Genome Database (MGD) 2019. }},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/30407599 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC6323923},
    volume = {47},
    year = {2019}
}
@article{Bachman2018,
    abstract = {For automated reading of scientific publications to extract useful information about molecular mechanisms it is critical that genes, proteins and other entities be correctly associated with uniform identifiers, a process known as named entity linking or “grounding.” Correct grounding is essential for resolving relationships among mined information, curated interaction databases, and biological datasets. The accuracy of this process is largely dependent on the availability of machine-readable resources associating synonyms and abbreviations commonly found in biomedical literature with uniform identifiers. In a task involving automated reading of ∼215,000 articles using the REACH event extraction software we found that grounding was disproportionately inaccurate for multi-protein families (e.g., “AKT”) and complexes with multiple subunits (e.g.“NF- $\kappa$B”). To address this problem we constructed FamPlex, a manually curated resource defining protein families and complexes as they are commonly encountered in biomedical text. In FamPlex the gene-level constituents of families and complexes are defined in a flexible format allowing for multi-level, hierarchical membership. To create FamPlex, text strings corresponding to entities were identified empirically from literature and linked manually to uniform identifiers; these identifiers were also mapped to equivalent entries in multiple related databases. FamPlex also includes curated prefix and suffix patterns that improve named entity recognition and event extraction. Evaluation of REACH extractions on a test corpus of ∼54,000 articles showed that FamPlex significantly increased grounding accuracy for families and complexes (from 15 to 71 { \% } ). The hierarchical organization of entities in FamPlex also made it possible to integrate otherwise unconnected mechanistic information across families, subfamilies, and individual proteins. Applications of FamPlex to the TRIPS/DRUM reading system and the Biocreative VI Bioentity Normalization Task dataset demonstrated the utility of FamPlex in other settings. FamPlex is an effective resource for improving named entity recognition, grounding, and relationship resolution in automated reading of biomedical text. The content in FamPlex is available in both tabular and Open Biomedical Ontology formats at
 https://github.com/sorgerlab/famplex


 under the Creative Commons CC0 license and has been integrated into the TRIPS/DRUM and REACH reading systems.},
    author = {Bachman, John A. and Gyori, Benjamin M. and Sorger, Peter K.},
    doi = {10.1186/s12859-018-2211-5},
    file = {:Users/cthoyt/ownCloud/Mendeley/2018/FamPlex A resource for entity recognition and relationship resolution of human protein families and complexes in biomedical text mining.pdf:pdf},
    isbn = {14712105 (Electronic)},
    issn = {14712105},
    journal = {BMC Bioinformatics},
    keywords = {Biocuration,Event extraction,Grounding,Named entity linking,Named entity recognition,Natural language processing,Protein families,Text mining},
    mendeley-groups = {Thesis try 2},
    number = {1},
    pages = {1--14},
    pmid = {29954318},
    publisher = {BMC Bioinformatics},
    title = {{ FamPlex: A resource for entity recognition and relationship resolution of human protein families and complexes in biomedical text mining }},
    volume = {19},
    year = {2018}
}

@article{Hobbs1978,
    abstract = {Two approaches to the problem of resolving pronoun references are presented. The first is a naive algorithm that works by traversing the surface parse trees of the sentences of the text in a particular order looking for noun phrases of the correct gender and number. The algorithm clearly does not work in all cases, but the results of an examination of several hundred examples from published texts show that it performs remarkably well. In the second approach, it is shown how pronoun solution can be handled in a comprehensive system for semantic analysis of English texts. The system is described, and it is shown in a detailed treatment of several examples how semantic analysis locates the antecedents of most pronouns as a by-product. Included are the classic examples of Winograd and Charniak.},
    author = {Hobbs, Jerry R},
    doi = {https://doi.org/10.1016/0024-3841(78)90006-2},
    issn = {0024-3841},
    journal = {Lingua},
    mendeley-groups = {Thesis try 2},
    number = {4},
    pages = {311--338},
    title = {{ Resolving pronoun references }},
    url = {http://www.sciencedirect.com/science/article/pii/0024384178900062},
    volume = {44},
    year = {1978}
}

@inproceedings{Brennan1987,
    author = {Brennan, Susan E. and Friedman, Marilyn W. and Pollard, Carl J.},
    title = {A Centering Approach to Pronouns},
    booktitle = {Proceedings of the 25th Annual Meeting on Association for Computational Linguistics},
    series = {ACL '87},
    year = {1987},
    location = {Stanford, California},
    pages = {155--162},
    numpages = {8},
    url = {https://doi.org/10.3115/981175.981197},
    doi = {10.3115/981175.981197},
    acmid = {981197},
    publisher = {Association for Computational Linguistics},
    address = {Stroudsburg, PA, USA},
}

@article{Lappin1994,
    author = {Lappin, Shalom and Leass, Herbert J.},
    title = {An Algorithm for Pronominal Anaphora Resolution},
    journal = {Comput. Linguist.},
    issue_date = {December 1994},
    volume = {20},
    number = {4},
    month = dec,
    year = {1994},
    issn = {0891-2017},
    pages = {535--561},
    numpages = {27},
    url = {http://dl.acm.org/citation.cfm?id=203987.203989},
    acmid = {203989},
    publisher = {MIT Press},
    address = {Cambridge, MA, USA},
}

@article{Soon2001,
    author = {Soon, Wee Meng and Ng, Hwee Tou and Lim, Daniel Chung Yong},
    title = {A Machine Learning Approach to Coreference Resolution of Noun Phrases},
    journal = {Comput. Linguist.},
    issue_date = {December 2001},
    volume = {27},
    number = {4},
    month = dec,
    year = {2001},
    issn = {0891-2017},
    pages = {521--544},
    numpages = {24},
    url = {http://dl.acm.org/citation.cfm?id=972597.972602},
    acmid = {972602},
    publisher = {MIT Press},
    address = {Cambridge, MA, USA},
}

@inproceedings{Ng2002,
    author = {Ng, Vincent and Cardie, Claire},
    title = {Identifying Anaphoric and Non-anaphoric Noun Phrases to Improve Coreference Resolution},
    booktitle = {Proceedings of the 19th International Conference on Computational Linguistics - Volume 1},
    series = {COLING '02},
    year = {2002},
    location = {Taipei, Taiwan},
    pages = {1--7},
    numpages = {7},
    url = {https://doi.org/10.3115/1072228.1072367},
    doi = {10.3115/1072228.1072367},
    acmid = {1072367},
    publisher = {Association for Computational Linguistics},
    address = {Stroudsburg, PA, USA},
}

@inproceedings{Bengtson2008,
    author = {Bengtson, Eric and Roth, Dan},
    title = {Understanding the Value of Features for Coreference Resolution},
    booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing},
    series = {EMNLP '08},
    year = {2008},
    location = {Honolulu, Hawaii},
    pages = {294--303},
    numpages = {10},
    url = {http://dl.acm.org/citation.cfm?id=1613715.1613756},
    acmid = {1613756},
    publisher = {Association for Computational Linguistics},
    address = {Stroudsburg, PA, USA},
}

@inproceedings{Luo2004,
    author = {Luo, Xiaoqiang and Ittycheriah, Abe and Jing, Hongyan and Kambhatla, Nanda and Roukos, Salim},
    title = {A Mention-synchronous Coreference Resolution Algorithm Based on the Bell Tree},
    booktitle = {Proceedings of the 42Nd Annual Meeting on Association for Computational Linguistics},
    series = {ACL '04},
    year = {2004},
    location = {Barcelona, Spain},
    articleno = {135},
    url = {https://doi.org/10.3115/1218955.1218973},
    doi = {10.3115/1218955.1218973},
    acmid = {1218973},
    publisher = {Association for Computational Linguistics},
    address = {Stroudsburg, PA, USA},
}

@inproceedings{Yang2004,
    author = {Yang, Xiaofeng and Su, Jian and Zhou, Guodong and Tan, Chew Lim},
    title = {An NP-cluster Based Approach to Coreference Resolution},
    booktitle = {Proceedings of the 20th International Conference on Computational Linguistics},
    series = {COLING '04},
    year = {2004},
    location = {Geneva, Switzerland},
    articleno = {226},
    url = {https://doi.org/10.3115/1220355.1220388},
    doi = {10.3115/1220355.1220388},
    acmid = {1220388},
    publisher = {Association for Computational Linguistics},
    address = {Stroudsburg, PA, USA},
}

@inproceedings{Yang2008,
    author = {Yang, Xiaofeng and Su, Jian and Lang, Jun and Tan, Chew Lim and Liu, Ting and Li, Sheng},
    title = {An Entity-Mention Model for Coreference Resolution with Inductive Logic Programming},
    booktitle = {Proceedings of ACL-08: HLT},
    month = {June},
    year = {2008},
    address = {Columbus, Ohio},
    publisher = {Association for Computational Linguistics},
    pages = {843--851},
    url = {http://www.aclweb.org/anthology/P/P08/P08-1096}
}

@inproceedings{Lee2011,
    author = {Lee, Heeyoung and Peirsman, Yves and Chang, Angel and Chambers, Nathanael and Surdeanu, Mihai and Jurafsky, Dan},
    title = {Stanford's Multi-pass Sieve Coreference Resolution System at the CoNLL-2011 Shared Task},
    booktitle = {Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task},
    series = {CONLL Shared Task '11},
    year = {2011},
    isbn = {9781937284084},
    location = {Portland, Oregon},
    pages = {28--34},
    numpages = {7},
    url = {http://dl.acm.org/citation.cfm?id=2132936.2132938},
    acmid = {2132938},
    publisher = {Association for Computational Linguistics},
    address = {Stroudsburg, PA, USA},
}

@inproceedings{Denis2007,
    author = {Denis, Pascal and Baldridge, Jason},
    title = {A Ranking Approach to Pronoun Resolution},
    booktitle = {Proceedings of the 20th International Joint Conference on Artifical Intelligence},
    series = {IJCAI'07},
    year = {2007},
    location = {Hyderabad, India},
    pages = {1588--1593},
    numpages = {6},
    url = {http://dl.acm.org/citation.cfm?id=1625275.1625532},
    acmid = {1625532},
    publisher = {Morgan Kaufmann Publishers Inc.},
    address = {San Francisco, CA, USA},
}

@inproceedings{Rahman2009,
    author = {Rahman, Altaf and Ng, Vincent},
    title = {Supervised Models for Coreference Resolution},
    booktitle = {Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2 - Volume 2},
    series = {EMNLP '09},
    year = {2009},
    isbn = {978-1-932432-62-6},
    location = {Singapore},
    pages = {968--977},
    numpages = {10},
    url = {http://dl.acm.org/citation.cfm?id=1699571.1699639},
    acmid = {1699639},
    publisher = {Association for Computational Linguistics},
    address = {Stroudsburg, PA, USA},
}

@article{martschat2015,
    title = {Latent Structures for Coreference Resolution},
    author = "Martschat, Sebastian and Strube, Michael",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "3",
    year = "2015",
    url = "https://www.aclweb.org/anthology/Q15-1029",
    doi = "10.1162/tacl_a_00147",
    pages = "405--418",
    abstract = {Machine learning approaches to coreference resolution vary greatly in the modeling of the problem: while early approaches operated on the mention pair level, current research focuses on ranking architectures and antecedent trees. We propose a unified representation of different approaches to coreference resolution in terms of the structure they operate on. We represent several coreference resolution approaches proposed in the literature in our framework and evaluate their performance. Finally, we conduct a systematic analysis of the output of these approaches, highlighting differences and similarities.},
}

@article{Rahman2011,
    author = {Rahman, Altaf and Ng, Vincent},
    title = {Narrowing the Modeling Gap: A Cluster-ranking Approach to Coreference Resolution},
    journal = {J. Artif. Int. Res.},
    issue_date = {January 2011},
    volume = {40},
    number = {1},
    month = jan,
    year = {2011},
    issn = {1076-9757},
    pages = {469--521},
    numpages = {53},
    url = {http://dl.acm.org/citation.cfm?id=2016945.2016958},
    acmid = {2016958},
    publisher = {AI Access Foundation},
    address = {USA},
}

@inproceedings{Ma2014,
    address = {Stroudsburg, PA, USA},
    author = {Ma, Chao and Doppa, Janardhan Rao and Orr, J. Walker and Mannem, Prashanth and Fern, Xiaoli and Dietterich, Tom and Tadepalli, Prasad},
    booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
    doi = {10.3115/v1/D14-1225},
    pages = {2115--2126},
    publisher = {Association for Computational Linguistics},
    title = {{ Prune-and-Score: Learning for Greedy Coreference Resolution }},
    url = {http://aclweb.org/anthology/D14-1225},
    year = {2014}
}

@inproceedings{Clark2016,
    title = "Improving Coreference Resolution by Learning Entity-Level Distributed Representations",
    author = {Clark, Kevin and Manning, Christopher D.},
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P16-1061",
    doi = "10.18653/v1/P16-1061",
    pages = "643--653",
}

@article{Li2018,
    author = {Li, Chen and Rao, Zhiqiang and Zheng, Qinghua and Zhang, Xiangrong},
    title = "{A set of domain rules and a deep network for protein coreference resolution}",
    journal = {Database},
    volume = {2018},
    year = {2018},
    month = {07},
    issn = {1758-0463},
    doi = {10.1093/database/bay065},
    url = {https://doi.org/10.1093/database/bay065},
    eprint = {http://oup.prod.sis.lan/database/article-pdf/doi/10.1093/database/bay065/27438328/bay065.pdf},
}

@article{Giorgi526244,
    author = {Giorgi, John and Bader, Gary},
    title = {Towards reliable named entity recognition in the biomedical domain},
    elocation-id = {526244},
    year = {2019},
    doi = {10.1101/526244},
    publisher = {Cold Spring Harbor Laboratory},
    URL = {https://www.biorxiv.org/content/early/2019/01/22/526244},
    eprint = {https://www.biorxiv.org/content/early/2019/01/22/526244.full.pdf},
    journal = {bioRxiv}
}

@article{Hakenberg2011,
    abstract = {SUMMARY Identifying mentions of named entities, such as genes or diseases, and normalizing them to database identifiers have become an important step in many text and data mining pipelines. Despite this need, very few entity normalization systems are publicly available as source code or web services for biomedical text mining. Here we present the Gnat Java library for text retrieval, named entity recognition, and normalization of gene and protein mentions in biomedical text. The library can be used as a component to be integrated with other text-mining systems, as a framework to add user-specific extensions, and as an efficient stand-alone application for the identification of gene and protein names for data analysis. On the BioCreative III test data, the current version of Gnat achieves a Tap-20 score of 0.1987. AVAILABILITY The library and web services are implemented in Java and the sources are available from http://gnat.sourceforge.net. CONTACT jorg.hakenberg@roche.com.},
    author = {Hakenberg, J { \" { o } } rg and Gerner, Martin and Haeussler, Maximilian and Solt, Ill { \' { e } } s and Plake, Conrad and Schroeder, Michael and Gonzalez, Graciela and Nenadic, Goran and Bergman, Casey M},
    doi = {10.1093/bioinformatics/btr455},
    issn = {1367-4811},
    journal = {Bioinformatics (Oxford, England)},
    mendeley-groups = {Thesis try 2},
    month = {oct},
    number = {19},
    pages = {2769--71},
    pmid = {21813477},
    title = {{ The GNAT library for local and remote gene mention normalization. }},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/21813477 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3179658},
    volume = {27},
    year = {2011}
}

@article{Hakenberg2011,
    abstract = {SUMMARY Identifying mentions of named entities, such as genes or diseases, and normalizing them to database identifiers have become an important step in many text and data mining pipelines. Despite this need, very few entity normalization systems are publicly available as source code or web services for biomedical text mining. Here we present the Gnat Java library for text retrieval, named entity recognition, and normalization of gene and protein mentions in biomedical text. The library can be used as a component to be integrated with other text-mining systems, as a framework to add user-specific extensions, and as an efficient stand-alone application for the identification of gene and protein names for data analysis. On the BioCreative III test data, the current version of Gnat achieves a Tap-20 score of 0.1987. AVAILABILITY The library and web services are implemented in Java and the sources are available from http://gnat.sourceforge.net. CONTACT jorg.hakenberg@roche.com.},
    author = {Hakenberg, J { \" { o } } rg and Gerner, Martin and Haeussler, Maximilian and Solt, Ill { \' { e } } s and Plake, Conrad and Schroeder, Michael and Gonzalez, Graciela and Nenadic, Goran and Bergman, Casey M},
    doi = {10.1093/bioinformatics/btr455},
    issn = {1367-4811},
    journal = {Bioinformatics (Oxford, England)},
    mendeley-groups = {Thesis try 2},
    month = {oct},
    number = {19},
    pages = {2769--71},
    pmid = {21813477},
    title = {{ The GNAT library for local and remote gene mention normalization. }},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/21813477 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3179658},
    volume = {27},
    year = {2011}
}

@article{Hsu2008,
    abstract = {MOTIVATION Tagging gene and gene product mentions in scientific text is an important initial step of literature mining. In this article, we describe in detail our gene mention tagger participated in BioCreative 2 challenge and analyze what contributes to its good performance. Our tagger is based on the conditional random fields model (CRF), the most prevailing method for the gene mention tagging task in BioCreative 2. Our tagger is interesting because it accomplished the highest F-scores among CRF-based methods and second over all. Moreover, we obtained our results by mostly applying open source packages, making it easy to duplicate our results. RESULTS We first describe in detail how we developed our CRF-based tagger. We designed a very high dimensional feature set that includes most of information that may be relevant. We trained bi-directional CRF models with the same set of features, one applies forward parsing and the other backward, and integrated two models based on the output scores and dictionary filtering. One of the most prominent factors that contributes to the good performance of our tagger is the integration of an additional backward parsing model. However, from the definition of CRF, it appears that a CRF model is symmetric and bi-directional parsing models will produce the same results. We show that due to different feature settings, a CRF model can be asymmetric and the feature setting for our tagger in BioCreative 2 not only produces different results but also gives backward parsing models slight but constant advantage over forward parsing model. To fully explore the potential of integrating bi-directional parsing models, we applied different asymmetric feature settings to generate many bi-directional parsing models and integrate them based on the output scores. Experimental results show that this integrated model can achieve even higher F-score solely based on the training corpus for gene mention tagging. AVAILABILITY Data sets, programs and an on-line service of our gene mention tagger can be accessed at http://aiia.iis.sinica.edu.tw/biocreative2.htm.},
    author = {Hsu, Chun-Nan and Chang, Yu-Ming and Kuo, Cheng-Ju and Lin, Yu-Shi and Huang, Han-Shen and Chung, I-Fang},
    doi = {10.1093/bioinformatics/btn183},
    issn = {1367-4811},
    journal = {Bioinformatics (Oxford, England)},
    mendeley-groups = {Thesis try 2},
    month = {jul},
    number = {13},
    pages = {i286--94},
    pmid = {18586726},
    title = {{ Integrating high dimensional bi-directional parsing models for gene mention tagging. }},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/18586726 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2718659},
    volume = {24},
    year = {2008}
}

@article{Leaman2008,
    abstract = {There has been an increasing amount of research on biomedical named entity recognition, the most basic text extraction problem, resulting in significant progress by different research teams around the world. This has created a need for a freely-available, open source system implementing the advances described in the literature. In this paper we present BANNER, an open-source, executable survey of advances in biomedical named entity recognition, intended to serve as a benchmark for the field. BANNER is implemented in Java as a machine-learning system based on conditional random fields and includes a wide survey of the best techniques recently described in the literature. It is designed to maximize domain independence by not employing brittle semantic features or rule-based processing steps, and achieves significantly better performance than existing baseline systems. It is therefore useful to developers as an extensible NER implementation, to researchers as a standard for comparing innovative techniques, and to biologists requiring the ability to find novel entities in large amounts of text.},
    author = {Leaman, Robert and Gonzalez, Graciela},
    issn = {2335-6928},
    journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
    mendeley-groups = {Thesis try 2},
    pages = {652--63},
    pmid = {18229723},
    title = {{ BANNER: an executable survey of advances in biomedical named entity recognition. }},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/18229723},
    year = {2008}
}

@article{Wei2015,
    abstract = {The automatic recognition of gene names and their associated database identifiers from biomedical text has been widely studied in recent years, as these tasks play an important role in many downstream text-mining applications. Despite significant previous research, only a small number of tools are publicly available and these tools are typically restricted to detecting only mention level gene names or only document level gene identifiers. In this work, we report GNormPlus: an end-to-end and open source system that handles both gene mention and identifier detection. We created a new corpus of 694 PubMed articles to support our development of GNormPlus, containing manual annotations for not only gene names and their identifiers, but also closely related concepts useful for gene name disambiguation, such as gene families and protein domains. GNormPlus integrates several advanced text-mining techniques, including SimConcept for resolving composite gene names. As a result, GNormPlus compares favorably to other state-of-the-art methods when evaluated on two widely used public benchmarking datasets, achieving 86.7 { \% } F1-score on the BioCreative II Gene Normalization task dataset and 50.1 { \% } F1-score on the BioCreative III Gene Normalization task dataset. The GNormPlus source code and its annotated corpus are freely available, and the results of applying GNormPlus to the entire PubMed are freely accessible through our web-based tool PubTator.},
    author = {Wei, Chih-Hsuan and Kao, Hung-Yu and Lu, Zhiyong},
    doi = {10.1155/2015/918710},
    issn = {2314-6141},
    journal = {BioMed research international},
    mendeley-groups = {Thesis try 2},
    pages = {918710},
    pmid = {26380306},
    title = {{ GNormPlus: An Integrative Approach for Tagging Genes, Gene Families, and Protein Domains. }},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/26380306 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4561873},
    volume = {2015},
    year = {2015}
}

@article{Leaman2015,
    abstract = {Chemical compounds and drugs are an important class of entities in biomedical research with great potential in a wide range of applications, including clinical medicine. Locating chemical named entities in the literature is a useful step in chemical text mining pipelines for identifying the chemical mentions, their properties, and their relationships as discussed in the literature. We introduce the tmChem system, a chemical named entity recognizer created by combining two independent machine learning models in an ensemble. We use the corpus released as part of the recent CHEMDNER task to develop and evaluate tmChem, achieving a micro-averaged f-measure of 0.8739 on the CEM subtask (mention-level evaluation) and 0.8745 f-measure on the CDI subtask (abstract-level evaluation). We also report a high-recall combination (0.9212 for CEM and 0.9224 for CDI). tmChem achieved the highest f-measure reported in the CHEMDNER task for the CEM subtask, and the high recall variant achieved the highest recall on both the CEM and CDI tasks. We report that tmChem is a state-of-the-art tool for chemical named entity recognition and that performance for chemical named entity recognition has now tied (or exceeded) the performance previously reported for genes and diseases. Future research should focus on tighter integration between the named entity recognition and normalization steps for improved performance. The source code and a trained model for both models of tmChem is available at: http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/tmChem. The results of running tmChem (Model 2) on PubMed are available in PubTator: http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/PubTator.},
    author = {Leaman, Robert and Wei, Chih-Hsuan and Lu, Zhiyong},
    doi = {10.1186/1758-2946-7-S1-S3},
    issn = {1758-2946},
    journal = {Journal of cheminformatics},
    mendeley-groups = {Thesis try 2},
    number = {Suppl 1 Text mining for chemistry and the CHEMDNER track},
    pages = {S3},
    pmid = {25810774},
    title = {{ tmChem: a high performance approach for chemical named entity recognition and normalization. }},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/25810774 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4331693},
    volume = {7},
    year = {2015}
}

@article{Corbett2018,
    abstract = {Chemical named entity recognition (NER) has traditionally been dominated by conditional random fields (CRF)-based approaches but given the success of the artificial neural network techniques known as ``deep learning'' we decided to examine them as an alternative to CRFs. We present here several chemical named entity recognition systems. The first system translates the traditional CRF-based idioms into a deep learning framework, using rich per-token features and neural word embeddings, and producing a sequence of tags using bidirectional long short term memory (LSTM) networks---a type of recurrent neural net. The second system eschews the rich feature set---and even tokenisation---in favour of character labelling using neural character embeddings and multiple LSTM layers. The third system is an ensemble that combines the results of the first two systems. Our original BioCreative V.5 competition entry was placed in the top group with the highest F scores, and subsequent using transfer learning have achieved a final F score of 90.33 { \% } on the test data (precision 91.47 { \% } , recall 89.21 { \% } ).},
    author = {Corbett, Peter and Boyle, John},
    doi = {10.1186/s13321-018-0313-8},
    file = {:Users/cthoyt/ownCloud/Mendeley/2018/Chemlistem chemical named entity recognition using recurrent neural networks - 2018 - Corbett, Boyle.pdf:pdf},
    issn = {1758-2946},
    journal = {Journal of Cheminformatics},
    month = {dec},
    number = {1},
    pages = {59},
    title = {{ Chemlistem: chemical named entity recognition using recurrent neural networks }},
    url = {https://doi.org/10.1186/s13321-018-0313-8},
    volume = {10},
    year = {2018}
}

@article{Leaman2013,
    abstract = {MOTIVATION Despite the central role of diseases in biomedical research, there have been much fewer attempts to automatically determine which diseases are mentioned in a text-the task of disease name normalization (DNorm)-compared with other normalization tasks in biomedical text mining research. METHODS In this article we introduce the first machine learning approach for DNorm, using the NCBI disease corpus and the MEDIC vocabulary, which combines MeSH { \textregistered } and OMIM. Our method is a high-performing and mathematically principled framework for learning similarities between mentions and concept names directly from training data. The technique is based on pairwise learning to rank, which has not previously been applied to the normalization task but has proven successful in large optimization problems for information retrieval. RESULTS We compare our method with several techniques based on lexical normalization and matching, MetaMap and Lucene. Our algorithm achieves 0.782 micro-averaged F-measure and 0.809 macro-averaged F-measure, an increase over the highest performing baseline method of 0.121 and 0.098, respectively. AVAILABILITY The source code for DNorm is available at http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/DNorm, along with a web-based demonstration and links to the NCBI disease corpus. Results on PubMed abstracts are available in PubTator: http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/PubTator .},
    author = {Leaman, Robert and { Islamaj Dogan } , Rezarta and Lu, Zhiyong},
    doi = {10.1093/bioinformatics/btt474},
    issn = {1367-4811},
    journal = {Bioinformatics (Oxford, England)},
    month = {nov},
    number = {22},
    pages = {2909--17},
    pmid = {23969135},
    title = {{ DNorm: disease name normalization with pairwise learning to rank. }},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/23969135 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3810844},
    volume = {29},
    year = {2013}
}

@article{Gerner2010,
    abstract = {BACKGROUND: The task of recognizing and identifying species names in biomedical literature has recently been regarded as critical for a number of applications in text and data mining, including gene name recognition, species-specific document retrieval, and semantic enrichment of biomedical articles. RESULTS: In this paper we describe an open-source species name recognition and normalization software system, LINNAEUS, and evaluate its performance relative to several automatically generated biomedical corpora, as well as a novel corpus of full-text documents manually annotated for species mentions. LINNAEUS uses a dictionary-based approach (implemented as an efficient deterministic finite-state automaton) to identify species names and a set of heuristics to resolve ambiguous mentions. When compared against our manually annotated corpus, LINNAEUS performs with 94 { \% } recall and 97 { \% } precision at the mention level, and 98 { \% } recall and 90 { \% } precision at the document level. Our system successfully solves the problem of disambiguating uncertain species mentions, with 97 { \% } of all mentions in PubMed Central full-text documents resolved to unambiguous NCBI taxonomy identifiers. CONCLUSIONS: LINNAEUS is an open source, stand-alone software system capable of recognizing and normalizing species name mentions with speed and accuracy, and can therefore be integrated into a range of bioinformatics and text-mining applications. The software and manually annotated corpus can be downloaded freely at http://linnaeus.sourceforge.net/.},
    author = {Gerner, Martin and Nenadic, Goran and Bergman, Casey M.},
    doi = {10.1186/1471-2105-11-85},
    file = {:Users/cthoyt/ownCloud/Mendeley/2010/LINNAEUS A species name identification system for biomedical literature - 2010 - Gerner, Nenadic, Bergman.pdf:pdf},
    issn = {14712105},
    journal = {BMC Bioinformatics},
    title = {{ LINNAEUS: A species name identification system for biomedical literature }},
    volume = {11},
    year = {2010}
}

@article{Wei2012,
    abstract = {As suggested in recent studies, species recognition and disambiguation is one of the most critical and challenging steps in many downstream text-mining applications such as the gene normalization task and protein-protein interaction extraction. We report SR4GN: an open source tool for species recognition and disambiguation in biomedical text. In addition to the species detection function in existing tools, SR4GN is optimized for the Gene Normalization task. As such it is developed to link detected species with corresponding gene mentions in a document. SR4GN achieves 85.42 { \% } in accuracy and compares favorably to the other state-of-the-art techniques in benchmark experiments. Finally, SR4GN is implemented as a standalone software tool, thus making it convenient and robust for use in many text-mining applications. SR4GN can be downloaded at: http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/downloads/SR4GN.},
    author = {Wei, Chih Hsuan and Kao, Hung Yu and Lu, Zhiyong},
    doi = {10.1371/journal.pone.0038460},
    file = {:Users/cthoyt/ownCloud/Mendeley/2012/SR4GN A Species Recognition Software Tool for Gene Normalization - 2012 - Wei, Kao, Lu.PDF:PDF},
    issn = {19326203},
    journal = {PLoS ONE},
    number = {6},
    pages = {7--11},
    title = {{ SR4GN: A species recognition software tool for gene normalization }},
    volume = {7},
    year = {2012}
}

@article{Lee2015,
    abstract = {Disease plays a central role in many areas of biomedical research and healthcare. However, the rapid growth of disease and treatment research creates barriers to the knowledge aggregation of PubMed database. Thus, a framework of disease mention recognition and normalization has become increasingly important for biomedical text mining. In this work, we utilize conditional random fields (CRFs) to develop a recognition system and optimize the results by customizing several post-processing steps, such as abbreviation resolution and consistency improvement. At the DNER subtask of BioCreative V CDR task, the system performance of disease normalization is 0.8646 of F-measure, especially a high precision (0.8963) on the normalization task.},
    author = {Lee, Hsin-Chun and Hsu, Yi-Yu and Kao, Hung-Yu},
    file = {:Users/cthoyt/ownCloud/Mendeley/2015/An enhanced CRF-based system for disease name entity recognition and normalization on BioCreative V DNER Task - 2015 - Lee, Hsu, Kao.pdf:pdf},
    journal = {Proceedings of the Fifth BioCreative Challenge Evaluation Workshop},
    keywords = {and normalization,biomedical text mining,conditional,disease name entity recognition,random fields},
    pages = {226--233},
    title = {{ An enhanced CRF-based system for disease name entity recognition and normalization on BioCreative V DNER Task }},
    year = {2015}
}

@article{Davis2012,
    abstract = {The Comparative Toxicogenomics Database (CTD) is a public resource that promotes understanding about the effects of environmental chemicals on human health. CTD biocurators manually curate a triad of chemical-gene, chemical-disease and gene-disease relationships from the scientific literature. The CTD curation paradigm uses controlled vocabularies for chemicals, genes and diseases. To curate disease information, CTD first had to identify a source of controlled terms. Two resources seemed to be good candidates: the Online Mendelian Inheritance in Man (OMIM) and the 'Diseases' branch of the National Library of Medicine's Medical Subject Headers (MeSH). To maximize the advantages of both, CTD biocurators undertook a novel initiative to map the flat list of OMIM disease terms into the hierarchical nature of the MeSH vocabulary. The result is CTD's 'merged disease vocabulary' (MEDIC), a unique resource that integrates OMIM terms, synonyms and identifiers with MeSH terms, synonyms, definitions, identifiers and hierarchical relationships. MEDIC is both a deep and broad vocabulary, composed of 9700 unique diseases described by more than 67 000 terms (including synonyms). It is freely available to download in various formats from CTD. While neither a true ontology nor a perfect solution, this vocabulary has nonetheless proved to be extremely successful and practical for our biocurators in generating over 2.5 million disease-associated toxicogenomic relationships in CTD. Other external databases have also begun to adopt MEDIC for their disease vocabulary. Here, we describe the construction, implementation, maintenance and use of MEDIC to raise awareness of this resource and to offer it as a putative scaffold in the formal construction of an official disease ontology. DATABASE URL: http://ctd.mdibl.org/voc.go?type=disease.},
    author = {Davis, Allan Peter and Wiegers, Thomas C. and Rosenstein, Michael C. and Mattingly, Carolyn J.},
    doi = {10.1093/database/bar065},
    issn = {17580463},
    journal = {Database},
    pages = {1--9},
    title = {{ MEDIC: A practical disease vocabulary used at the comparative toxicogenomics database }},
    volume = {2012},
    year = {2012}
}

@article{Kuo2009,
    abstract = {Background: To automatically process large quantities of biological literature for knowledge discovery and information curation, text mining tools are becoming essential. Abbreviation recognition is related to NER and can be considered as a pair recognition task of a terminology and its corresponding abbreviation from free text. The successful identification of abbreviation and its corresponding definition is not only a prerequisite to index terms of text databases to produce articles of related interests, but also a building block to improve existing gene mention tagging and gene normalization tools. Results: Our approach to abbreviation recognition (AR) is based on machine-learning, which exploits a novel set of rich features to learn rules from training data. Tested on the AB3P corpus, our system demonstrated a F-score of 89.90 { \% } with 95.86 { \% } precision at 84.64 { \% } recall, higher than the result achieved by the existing best AR performance system. We also annotated a new corpus of 1200 PubMed abstracts which was derived from BioCreative II gene normalization corpus. On our annotated corpus, our system achieved a F-score of 86.20 { \% } with 93.52 { \% } precision at 79.95 { \% } recall, which also outperforms all tested systems. Conclusion: By applying our system to extract all short form-long form pairs from all available PubMed abstracts, we have constructed BIOADI. Mining BIOADI reveals many interesting trends of bio-medical research. Besides, we also provide an off-line AR software in the download section on http://bioagent.iis.sinica.edu.tw/BIOADI/. ? 2009 Kuo et al; licensee BioMed Central Ltd.},
    author = {Kuo, Cheng Ju and Ling, Maurice H.T. and Lin, Kuan Ting and Hsu, Chun Nan},
    doi = {10.1186/1471-2105-10-S15-S7},
    file = {:Users/cthoyt/ownCloud/Mendeley/2009/and definitions in biological literature - 2009 - Kuo et al.pdf:pdf},
    isbn = {1471210510},
    issn = {14712105},
    journal = {BMC Bioinformatics},
    number = {SUPPL. 15},
    pages = {1--10},
    title = {{ BIOADI: A machine learning approach to identifying abbreviations and definitions in biological literature }},
    volume = {10},
    year = {2009}
}

@article{Mikolov2013,
    archivePrefix = {arXiv},
    arxivId = {1301.3781v3},
    author = {Mikolov, Tomas and Corrado, Greg and Chen, Kai and Dean, Jeffrey},
    eprint = {1301.3781v3},
    file = {:Users/cthoyt/ownCloud/Mendeley/2013/Efficient Estimation of Word Representations in Vector Space - 2013 - Mikolov et al.pdf:pdf},
    pages = {1--12},
    title = {{ Efficient Estimation of Word Representations in Vector Space }},
    year = {2013}
}

@article{Pennington2014,
    author = {{ Jeffrey Pennington } , Jeffrey and Socher, Richard and Manning, Christopher D.},
    file = {:Users/cthoyt/ownCloud/Mendeley/2014/Glove Global vectors for word representation - 2014 - Jeffrey Pennington, Socher, Manning.pdf:pdf},
    journal = {In EMNLP},
    title = {{ Glove: Global vectors for word representation }},
    year = {2014}
}

@article{Lample2016,
    abstract = {State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available. In this paper, we introduce two new neural architectures---one based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers. Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora. Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.},
    archivePrefix = {arXiv},
    arxivId = {1603.01360},
    author = {Lample, Guillaume and Ballesteros, Miguel and Subramanian, Sandeep and Kawakami, Kazuya and Dyer, Chris},
    eprint = {1603.01360},
    file = {:Users/cthoyt/ownCloud/Mendeley/2016/Neural Architectures for Named Entity Recognition - 2016 - Lample et al.pdf:pdf},
    pages = {260--270},
    title = {{ Neural Architectures for Named Entity Recognition }},
    url = {http://arxiv.org/abs/1603.01360},
    year = {2016}
}

@article{Kim2003,
    abstract = {MOTIVATION: Natural language processing (NLP) methods are regarded as being useful to raise the potential of text mining from biological literature. The lack of an extensively annotated corpus of this literature, however, causes a major bottleneck for applying NLP techniques. GENIA corpus is being developed to provide reference materials to let NLP techniques work for bio-textmining. RESULTS: GENIA corpus version 3.0 consisting of 2000 MEDLINE abstracts has been released with more than 400,000 words and almost 100,000 annotations for biological terms.},
    author = {Kim, J. D. and Ohta, T. and Tateisi, Y. and Tsujii, J.},
    doi = {10.1093/bioinformatics/btg1023},
    file = {:Users/cthoyt/ownCloud/Mendeley/2003/for bio-textmining - 2003 - Ohta, Tateisi, Tsujii.pdf:pdf},
    issn = {13674803},
    journal = {Bioinformatics},
    keywords = {Computational Molecular Biology,Corpus,Information Extraction,Natural Language Processing,Text Mining},
    number = {SUPPL. 1},
    pages = {180--182},
    title = {{ GENIA corpus - A semantically annotated corpus for bio-textmining }},
    volume = {19},
    year = {2003}
}

@article{Cote2006,
    abstract = {BACKGROUND: With the vast amounts of biomedical data being generated by high-throughput analysis methods, controlled vocabularies and ontologies are becoming increasingly important to annotate units of information for ease of search and retrieval. Each scientific community tends to create its own locally available ontology. The interfaces to query these ontologies tend to vary from group to group. We saw the need for a centralized location to perform controlled vocabulary queries that would offer both a lightweight web-accessible user interface as well as a consistent, unified SOAP interface for automated queries. RESULTS: The Ontology Lookup Service (OLS) was created to integrate publicly available biomedical ontologies into a single database. All modified ontologies are updated daily. A list of currently loaded ontologies is available online. The database can be queried to obtain information on a single term or to browse a complete ontology using AJAX. Auto-completion provides a user-friendly search mechanism. An AJAX-based ontology viewer is available to browse a complete ontology or subsets of it. A programmatic interface is available to query the webservice using SOAP. The service is described by a WSDL descriptor file available online. A sample Java client to connect to the webservice using SOAP is available for download from SourceForge. All OLS source code is publicly available under the open source Apache Licence. CONCLUSION: The OLS provides a user-friendly single entry point for publicly available ontologies in the Open Biomedical Ontology (OBO) format. It can be accessed interactively or programmatically at http://www.ebi.ac.uk/ontology-lookup/.},
    author = {Cote, RG and Jones, P and Apweiler, R and Hermjakob, H},
    doi = {10.1186/1471-2105-7-97},
    file = {:Users/cthoyt/ownCloud/Mendeley/2006/The Ontology Lookup Service, a lightweight cross-platform tool for controlled vocabulary queries. - 2006 - Cote et al.pdf:pdf;:Users/cthoyt/ownCloud/Mendeley/2006/The Ontology Lookup Service, a lightweight cross-platform tool for controlled vocabulary queries. - 2006 - Cote et al(2).pdf:pdf},
    issn = {1471-2105},
    journal = {BMC Bioinformatics},
    mendeley-groups = {Thesis,Paper Resources/PyBEL Application Note},
    pages = {1--7},
    pmid = {16507094},
    title = {{ The Ontology Lookup Service, a lightweight cross-platform tool for controlled vocabulary queries. }},
    volume = {7},
    year = {2006}
}
